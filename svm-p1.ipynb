{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-22T02:04:10.245110Z",
     "start_time": "2025-01-22T02:04:10.241053Z"
    }
   },
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T02:31:45.066486Z",
     "start_time": "2025-01-22T02:31:45.062359Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Leer activity_labels.txt\n",
    "\n",
    "activity_map = {}\n",
    "with open('activity_labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        label_id = int(parts[0])\n",
    "        label_name = \" \".join(parts[1:])\n",
    "        activity_map[label_id] = label_name\n",
    "\n",
    "print(\"Activity Map:\", activity_map)\n"
   ],
   "id": "1b87f28164bb8478",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity Map: {1: 'WALKING', 2: 'WALKING_UPSTAIRS', 3: 'WALKING_DOWNSTAIRS', 4: 'SITTING', 5: 'STANDING', 6: 'LAYING'}\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T15:42:23.340530Z",
     "start_time": "2025-01-22T15:42:22.983075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Leer archivos HDF5 (train.h5 CON y) y concatenar canales en un solo array\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def load_data_from_h5(filename, has_labels=True):\n",
    "\n",
    "    with h5py.File(filename, 'r') as f:\n",
    "        print(f\"Keys en {filename}:\", list(f.keys()))\n",
    "\n",
    "        if has_labels:\n",
    "            y_data = f['y'][:]\n",
    "        else:\n",
    "            y_data = None\n",
    "\n",
    "        body_acc_x   = f['body_acc_x'][:]\n",
    "        body_acc_y   = f['body_acc_y'][:]\n",
    "        body_acc_z   = f['body_acc_z'][:]\n",
    "        body_gyro_x  = f['body_gyro_x'][:]\n",
    "        body_gyro_y  = f['body_gyro_y'][:]\n",
    "        body_gyro_z  = f['body_gyro_z'][:]\n",
    "        total_acc_x  = f['total_acc_x'][:]\n",
    "        total_acc_y  = f['total_acc_y'][:]\n",
    "        total_acc_z  = f['total_acc_z'][:]\n",
    "\n",
    "        # Concatenar por columnas\n",
    "        X_data = np.concatenate([\n",
    "            body_acc_x, body_acc_y, body_acc_z,\n",
    "            body_gyro_x, body_gyro_y, body_gyro_z,\n",
    "            total_acc_x, total_acc_y, total_acc_z\n",
    "        ], axis=1)\n",
    "\n",
    "    return X_data, y_data\n",
    "\n",
    "X_train, y_train = load_data_from_h5('train.h5', has_labels=True)\n",
    "print(\"Shape de X_train:\", X_train.shape)\n",
    "print(\"Shape de y_train:\", y_train.shape)\n",
    "\n",
    "X_test, _ = load_data_from_h5('test.h5', has_labels=False)\n",
    "print(\"Shape de X_test:\", X_test.shape)\n"
   ],
   "id": "71b722abd00bcbdd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys en train.h5: ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z', 'y']\n",
      "Shape de X_train: (7352, 1152)\n",
      "Shape de y_train: (7352,)\n",
      "Keys en test.h5: ['body_acc_x', 'body_acc_y', 'body_acc_z', 'body_gyro_x', 'body_gyro_y', 'body_gyro_z', 'total_acc_x', 'total_acc_y', 'total_acc_z']\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'y' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 47\u001B[0m\n\u001B[0;32m     44\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape de y_train:\u001B[39m\u001B[38;5;124m\"\u001B[39m, y_train\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;66;03m# ====== Leer test.h5 (NO tiene etiquetas en Kaggle) ======\u001B[39;00m\n\u001B[1;32m---> 47\u001B[0m X_test, y_test_series \u001B[38;5;241m=\u001B[39m \u001B[43mload_data_from_h5\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtest.h5\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhas_labels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mShape de X_test:\u001B[39m\u001B[38;5;124m\"\u001B[39m, X_test\u001B[38;5;241m.\u001B[39mshape)\n",
      "Cell \u001B[1;32mIn[9], line 17\u001B[0m, in \u001B[0;36mload_data_from_h5\u001B[1;34m(filename, has_labels)\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Si el set contiene etiquetas\u001B[39;00m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_labels:\n\u001B[1;32m---> 17\u001B[0m     y_data \u001B[38;5;241m=\u001B[39m \u001B[43mf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43my\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m[:]\n\u001B[0;32m     18\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     19\u001B[0m     y_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\PycharmProjects\\project1_note\\.venv\\Lib\\site-packages\\h5py\\_hl\\group.py:357\u001B[0m, in \u001B[0;36mGroup.__getitem__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    355\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInvalid HDF5 object reference\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    356\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(name, (\u001B[38;5;28mbytes\u001B[39m, \u001B[38;5;28mstr\u001B[39m)):\n\u001B[1;32m--> 357\u001B[0m     oid \u001B[38;5;241m=\u001B[39m \u001B[43mh5o\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_e\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlapl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_lapl\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    358\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    359\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAccessing a group is done with bytes or str, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    360\u001B[0m                     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnot \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;28mtype\u001B[39m(name)))\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:54\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\_objects.pyx:55\u001B[0m, in \u001B[0;36mh5py._objects.with_phil.wrapper\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mh5py\\\\h5o.pyx:257\u001B[0m, in \u001B[0;36mh5py.h5o.open\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: \"Unable to synchronously open object (object 'y' doesn't exist)\""
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T02:31:52.690201Z",
     "start_time": "2025-01-22T02:31:50.118136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preparar datos de TRAIN para TSFresh\n",
    "import pandas as pd\n",
    "from tsfresh import extract_features, select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "def reshape_for_tsfresh(X, y=None):\n",
    "\n",
    "    n_muestras, n_features = X.shape\n",
    "    df_list = []\n",
    "    for i in range(n_muestras):\n",
    "        tmp = pd.DataFrame({\n",
    "            'id': np.repeat(i, n_features),\n",
    "            'time': np.arange(n_features),\n",
    "            'value': X[i, :]\n",
    "        })\n",
    "        df_list.append(tmp)\n",
    "    df_concat = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    if y is not None:\n",
    "        return df_concat, pd.Series(y, name='target')\n",
    "    else:\n",
    "        return df_concat\n",
    "\n",
    "df_train, y_train_series = reshape_for_tsfresh(X_train, y_train)\n",
    "print(\"df_train shape:\", df_train.shape)\n",
    "print(\"y_train_series shape:\", y_train_series.shape)\n"
   ],
   "id": "65316f611a9dd600",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_train shape: (8469504, 3)\n",
      "y_train_series shape: (7352,)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T02:56:06.006373Z",
     "start_time": "2025-01-22T02:31:58.593628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extracción de características\n",
    "extracted_features_train = extract_features(\n",
    "    df_train,\n",
    "    column_id='id',\n",
    "    column_sort='time',\n",
    "    column_value='value'\n",
    ")\n",
    "\n",
    "impute(extracted_features_train)\n",
    "\n",
    "# Seleccionar características relevantes basadas en y_train_series\n",
    "selected_features_train = select_features(extracted_features_train, y_train_series)\n",
    "\n",
    "print(\"extracted_features_train.shape =\", extracted_features_train.shape)\n",
    "print(\"selected_features_train.shape   =\", selected_features_train.shape)\n"
   ],
   "id": "9546ef883a390e7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [23:57<00:00, 47.92s/it]  \n",
      "C:\\Users\\david\\PycharmProjects\\project1_note\\.venv\\Lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:198: RuntimeWarning: The columns ['value__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_features_train.shape = (7352, 783)\n",
      "selected_features_train.shape   = (7352, 645)\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T03:07:19.724212Z",
     "start_time": "2025-01-22T02:57:21.553825Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Preprocesar X_test con las MISMAS features\n",
    "df_test = reshape_for_tsfresh(X_test, y=None)  # sin etiquetas\n",
    "print(\"df_test shape:\", df_test.shape)\n",
    "\n",
    "extracted_features_test = extract_features(\n",
    "    df_test,\n",
    "    column_id='id',\n",
    "    column_sort='time',\n",
    "    column_value='value'\n",
    ")\n",
    "\n",
    "impute(extracted_features_test)\n",
    "\n",
    "selected_features_test = extracted_features_test[selected_features_train.columns]\n",
    "print(\"extracted_features_test.shape =\", extracted_features_test.shape)\n",
    "print(\"selected_features_test.shape   =\", selected_features_test.shape)\n"
   ],
   "id": "bae3e9292ba5d50a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_test shape: (3394944, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 30/30 [09:55<00:00, 19.83s/it]  \n",
      "C:\\Users\\david\\PycharmProjects\\project1_note\\.venv\\Lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py:198: RuntimeWarning: The columns ['value__query_similarity_count__query_None__threshold_0.0'] did not have any finite values. Filling with zeros.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted_features_test.shape = (2947, 783)\n",
      "selected_features_test.shape   = (2947, 645)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T03:08:58.226321Z",
     "start_time": "2025-01-22T03:08:55.738636Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ENTRENAR MODELO SVM CON TRAIN Y PREDICCIONES EN TEST\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', C=1000.0, gamma='scale', random_state=42)\n",
    "svm_model.fit(selected_features_train, y_train_series)\n",
    "\n",
    "y_pred = svm_model.predict(selected_features_test)\n",
    "\n",
    "print(\"Predicciones en test (primeras 10):\", y_pred[:10])\n"
   ],
   "id": "f29a8ea7e62148e2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones en test (primeras 10): [5. 5. 5. 5. 5. 5. 5. 5. 5. 5.]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-22T03:09:18.609123Z",
     "start_time": "2025-01-22T03:09:18.598563Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generar submission CSV\n",
    "sample_ids = range(1, len(X_test) + 1)\n",
    "\n",
    "predicted_labels = y_pred.astype(int)  # Convertir a enteros\n",
    "\n",
    "# 3) Construir el DataFrame con encabezados requeridos\n",
    "submission_df = pd.DataFrame({\n",
    "    'ID': sample_ids,\n",
    "    'Activity': predicted_labels\n",
    "})\n",
    "\n",
    "submission_df.to_csv('submission5.csv', index=False)\n",
    "\n",
    "print(\"Archivo 'submission.csv' generado correctamente.\")\n"
   ],
   "id": "f3feadecce197b50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo 'submission.csv' generado correctamente.\n"
     ]
    }
   ],
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
